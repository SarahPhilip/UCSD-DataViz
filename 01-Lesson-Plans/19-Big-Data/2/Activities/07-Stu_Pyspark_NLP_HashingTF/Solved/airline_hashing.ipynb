{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                      Airline Tweets|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                            @VirginAmerica plus you've added commercials to the experience... tacky.|\n",
      "|@VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing. it's rea...|\n",
      "|                             @VirginAmerica do you miss me? Don't worry we'll be together very soon.|\n",
      "|       @VirginAmerica Are the hours of operation for the Club at SFO that are posted online current?|\n",
      "|@VirginAmerica awaiting my return phone call, just would prefer to use your online self-service o...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create session\n",
    "spark = SparkSession.builder.appName('idf').getOrCreate()\n",
    "\n",
    "# load data\n",
    "spark.sparkContext.addFile(\"https://s3.amazonaws.com/zepl-trilogy-test/airlines.csv\")\n",
    "df = spark.read.csv(SparkFiles.get(\"airlines.csv\"), sep=\",\", header=True)\n",
    "df.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                    Airline Tweets|                                             words|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|@VirginAmerica plus you've added commercials to...|[@virginamerica, plus, you've, added, commercia...|\n",
      "|@VirginAmerica seriously would pay $30 a flight...|[@virginamerica, seriously, would, pay, $30, a,...|\n",
      "|@VirginAmerica do you miss me? Don't worry we'l...|[@virginamerica, do, you, miss, me?, don't, wor...|\n",
      "|@VirginAmerica Are the hours of operation for t...|[@virginamerica, are, the, hours, of, operation...|\n",
      "|@VirginAmerica awaiting my return phone call, j...|[@virginamerica, awaiting, my, return, phone, c...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize dataframe\n",
    "tokened = Tokenizer(inputCol=\"Airline Tweets\", outputCol=\"words\")\n",
    "tokened_transformed = tokened.transform(df)\n",
    "tokened_transformed.show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|                   Airline Tweets|                            words|                         filtered|\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|@VirginAmerica plus you've add...|[@virginamerica, plus, you've,...|[plus, you've, added, commerci...|\n",
      "|@VirginAmerica seriously would...|[@virginamerica, seriously, wo...|[seriously, would, pay, a, fli...|\n",
      "|@VirginAmerica do you miss me?...|[@virginamerica, do, you, miss...|[do, you, miss, me?, don't, wo...|\n",
      "|@VirginAmerica Are the hours o...|[@virginamerica, are, the, hou...|[are, the, hours, of, operatio...|\n",
      "|@VirginAmerica awaiting my ret...|[@virginamerica, awaiting, my,...|[awaiting, my, return, phone, ...|\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop_list = [\"@VirginAmerica\", \"$30\", \"@virginamerica\"]\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", stopWords=stop_list)\n",
    "removed_frame = remover.transform(tokened_transformed)\n",
    "removed_frame.show(truncate=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|      Airline Tweets|               words|            filtered|        hashedValues|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|@VirginAmerica pl...|[@virginamerica, ...|[plus, you've, ad...|(16,[3,4,5,7,8,9,...|\n",
      "|@VirginAmerica se...|[@virginamerica, ...|[seriously, would...|(16,[0,1,2,3,4,9,...|\n",
      "|@VirginAmerica do...|[@virginamerica, ...|[do, you, miss, m...|(16,[0,1,8,10,11,...|\n",
      "|@VirginAmerica Ar...|[@virginamerica, ...|[are, the, hours,...|(16,[0,1,2,4,7,9,...|\n",
      "|@VirginAmerica aw...|[@virginamerica, ...|[awaiting, my, re...|(16,[0,3,4,6,7,8,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the hashing term frequency\n",
    "hashing = HashingTF(inputCol=\"filtered\", outputCol=\"hashedValues\", numFeatures=pow(2,4))\n",
    "\n",
    "# Transform into a DF\n",
    "hashed_df = hashing.transform(removed_frame)\n",
    "hashed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the IDF on the data set \n",
    "idf = IDF(inputCol=\"hashedValues\", outputCol=\"features\")\n",
    "idfModel = idf.fit(hashed_df)\n",
    "rescaledData = idfModel.transform(hashed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                          filtered|                                          features|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|[plus, you've, added, commercials, to, the, exp...|(16,[3,4,5,7,8,9,12,14],[0.4054651081081644,0.1...|\n",
      "|[seriously, would, pay, a, flight, for, seats, ...|(16,[0,1,2,3,4,9,11,12,13,14],[0.36464311358790...|\n",
      "|[do, you, miss, me?, don't, worry, we'll, be, t...|(16,[0,1,8,10,11,12,14,15],[0.1823215567939546,...|\n",
      "|[are, the, hours, of, operation, for, the, club...|(16,[0,1,2,4,7,9,11,12,14,15],[0.54696467038186...|\n",
      "|[awaiting, my, return, phone, call,, just, woul...|(16,[0,3,4,6,7,8,9,12,13,14,15],[0.364643113587...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "rescaledData.select(\"filtered\", \"features\").show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
